სახლების ფასების პროგნოზირება — Kaggle House Prices კონკურსი
მოკლე მიმოხილვა
პროექტი წარმოადგენს მონაწილეობას Kaggle-ის კონკურსში "House Prices - Advanced Regression Techniques", რომლის მიზანია საცხოვრებელი სახლების საბოლოო გაყიდვის ფასის პროგნოზირება არსებული თვისებების მიხედვით. მონაცემები მიღებულია train.csv და test.csv ფაილებიდან, რომლებიც კონკურსის ნაწილია.

პრობლემის გადაჭრის მიდგომა
პრობლემის გადასაჭრელად გამოყენებულია შემდეგი სტრატეგია:

მონაცემთა წინასწარი დამუშავება: მასშტაბირება, ტრანსფორმაცია და გაწმენდა ისე, რომ თითოეული ცვლადი წარმოდგენილი იყოს ანალიზისთვის ოპტიმალურ ფორმატში.

Feature Engineering და Data Cleaning:

კატეგორიული ცვლადების რიცხვითში გადაყვანა: გამოყენებულია ისეთი კოდირების მეთოდები, როგორიცაა OneHotEncoding და WOE, მონაცემთა შესატყვისი სტრუქტურაში გადაყვანისთვის.

ნაკლული (NaN) მნიშვნელობების შევსება: ცვლადები შეივსო შესაბამისი სტრატეგიებით — საშუალო, მოდა ან სპეციალური მნიშვნელობით.

მონაცემთა გაწმენდა: ამოღებულია დუბლიკატები და ექსტრემალური მნიშვნელობები (outliers).

მახასიათებლების შერჩევა (Feature Selection): გამოყენებულია კორელაციური ანალიზი და სხვა მეთოდები მხოლოდ ყველაზე რელევანტური ცვლადების შესარჩევად.

მოდელირება: გამოყენებულია სხვადასხვა რეგრესიული ალგორითმები პროგნოზის გაუმჯობესების მიზნით.

რეპოზიტორიის სტრუქტურა
model-experiment.ipynb — მოიცავს მონაცემების დამუშავებას, Feature Engineering-ს, სხვადასხვა მოდელის გადამზადებას (Gradient Boosting, Random Forest, Linear Regression) და მათ შეფასებას.

model-inference.ipynb — ფოკუსირებულია საბოლოოდ შერჩეული მოდელის გამოყენებით პროგნოზის შესრულებაზე.

ფაილების აღწერა
model-experiment.ipynb
მონაცემების ჩატვირთვა: train.csv და test.csv ფაილებიდან.

Feature Engineering:

კატეგორიული ცვლადების კოდირება: OneHotEncoder ან WOE კოდირება.

NaN მნიშვნელობების დამუშავება: შევსება მნიშნელობების მეშვეობით (საშუალო, მოდა, მულტიკლასის შევსება).

გაწმენდა: არასანდო ჩანაწერებისა და ანომალიების მოცილება.

მოდელების გადამზადება:

Gradient Boosting: გამოირჩევა მაღალი სიზუსტით და სტაბილურობით.

Random Forest: მდგრადი და უნივერსალური ალგორითმი.

Linear Regression: მარტივი და ინტერპრეტირებადი საბაზისო მოდელი.

Hyperparameter ოპტიმიზაცია:
შესრულებულია GridSearch ან RandomizedSearch მეთოდებით. გამოყენებულია Cross-Validation მაღალი სტაბილურობისთვის.

შეფასება: მოდელების შედარება შესრულდა R², RMSE და MAE მეტრიკებით.

model-inference.ipynb
ტესტის მონაცემების ჩატვირთვა და დამუშავება.

საბოლოო მოდელის ჩატვირთვა MLflow-დან.

პროგნოზირება დამუშავებული მონაცემებით.

შედეგების ექსპორტი CSV ფორმატში.

Feature Engineering დეტალები
კატეგორიული ცვლადების კოდირება: OneHotEncoder, WOE ან Target Encoding-ის გამოყენება ცვლადის ბუნებიდან გამომდინარე.

NaN მნიშვნელობების დამუშავება: ცვლადების შევსება ლოგიკაზე დაფუძნებით.

მონაცემთა გაწმენდა: ექსტრემალური მნიშვნელობებისა და არაკონსისტენტური ჩანაწერების მოცილება.

Feature Selection: კორელაციური ანალიზი, Variance Threshold და მოდელზე დაფუძნებული შერჩევა.

გამოყენებული მოდელები და მათი შეფასება
Gradient Boosting:
გამოირჩევა მაღალი სიზუსტით და ეფექტურობით, რაც უზრუნველყოფს პროგნოზების სტაბილურობას და სანდოობას.

Random Forest:
მძლავრი და მოქნილი მოდელი, რომელიც კარგად უმკლავდება მონაცემთა ჰეტეროგენურობას და ნაკლულობებს.

Linear Regression:
მარტივი და სწრაფი მოდელი, რომელიც გამოსადეგია ბაზისური შედარებისთვის და შედეგების ინტერპრეტაციისთვის.

Hyperparameter ოპტიმიზაცია
შესრულებულია სხვადასხვა ჰიპერპარამეტრის კომბინაციების ტესტირება. გამოყენებულია Cross-Validation, რათა უზრუნველყოფილ იქნას მოდელის გენერალიზაციის უნარი და სტაბილურობა.

MLflow Tracking
Tracking: ექსპერიმენტების ლოგირება და შედარება განხორციელდა MLflow-ის საშუალებით.

ექსპერიმენტების ბმული: (შეიყვანე ბმული, თუ გაქვს)

მეტრიკები:

R² Score: რეგრესიული მოდელის ახსნის უნარი.

RMSE: საშუალო კვადრატული შეცდომა.

MAE: საშუალო აბსოლუტური შეცდომა.

საუკეთესო მოდელის შედეგები:
მოდელი არჩეულია მიღწეული მეტრიკების საფუძველზე, რომლებიც აჩვენებენ მის სიზუსტეს და სტაბილურობას სხვადასხვა მონაცემზე.
